[
  {
    "objectID": "01-Introduction.html",
    "href": "01-Introduction.html",
    "title": "2  Topic 1",
    "section": "",
    "text": "2.1 Background",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Topic 1</span>"
    ]
  },
  {
    "objectID": "02-Chapter2.html",
    "href": "02-Chapter2.html",
    "title": "3  Chapter 2",
    "section": "",
    "text": "3.1 Background\nShow R code\nhist(rnorm(1000))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 2</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Toolbox",
    "section": "",
    "text": "1 Introduction\nThis is the Bayesian Toolbox from the Department of Clinical Research (DCR) of the University of Bern: A collection of resources and examples from consultings/projets of the DCR statistics group using Bayesian trial designs. This toolbox aims to support\n\nFuture consultings/projects with a foundation\nClinicians, statisticians and patients with examples of trial designs\nCommunication between clinicians, statisticians and patients",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "01-Chapter1.html",
    "href": "01-Chapter1.html",
    "title": "2  ABLATIO-BILICA",
    "section": "",
    "text": "2.1 Abbreviations",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ABLATIO-BILICA</span>"
    ]
  },
  {
    "objectID": "index.html#general-notation-and-abbreviations",
    "href": "index.html#general-notation-and-abbreviations",
    "title": "Bayesian Toolbox",
    "section": "1.1 General notation and abbreviations",
    "text": "1.1 General notation and abbreviations\n\niid: Independent and identically distributed.\npdf: Probability density function. Most often denoted as \\(f(\\cdot)\\). For bivariate pdf we use the notation \\(f_2(\\cdot)\\).\ncdf: Cumulative distribution function. Most often denoted as \\(F(\\cdot)\\). For bivariate pdf we use the notation \\(F_2(\\cdot)\\).\n\\(N_2\\): Bivariate cdf of the Gaussian distribution.\n\\(\\phi\\): pdf of the standard Gaussian distribution.\n\\(\\Phi\\): cdf of the standard Gaussian distribution.\n\\(\\Phi^{-1}\\): Quantile function of the standard Gaussian distribution function.\n\n\n\nShow R code\n1+2\n\n\n[1] 3",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "1. Lee\nJJ, Liu DD. A predictive probability design for phase II cancer clinical\ntrials. Clinical Trials. 2008;5: 93–106. doi:10.1177/1740774508089279\n\n\n2. Sambucini V. Efficacy and toxicity monitoring\nvia bayesian predictive probabilities in phase II clinical trials.\nStatistical Methods & Applications. 2021;30: 637–663. doi:10.1007/s10260-020-00537-3",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "01-Chapter1.html#primary-endpoint",
    "href": "01-Chapter1.html#primary-endpoint",
    "title": "2  ABLATIO-BILICA",
    "section": "2.2 Primary endpoint",
    "text": "2.2 Primary endpoint\nThe primary endpoint is any grade 3 or 4 adverse event (AE) leading to chemotherapy discontinuation up to six months after randomization. AE are assessed by the US National Cancer Institute Common Terminology Criteria for Adverse Events (CTCAE v5).\n\n\nShow R code\nhist(rnorm(1000))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ABLATIO-BILICA</span>"
    ]
  },
  {
    "objectID": "01-Chapter1.html#methods",
    "href": "01-Chapter1.html#methods",
    "title": "2  ABLATIO-BILICA",
    "section": "2.2 Methods",
    "text": "2.2 Methods\n\n2.2.1 Study intervention\nControl arm: Chemotherapy, durvalumab and endoscopic stenting.\nExperimental arm: Chemotherapy, durvalumab, endoscopic stenting plus intraductal bRFA.\n\n\n2.2.2 Primary endpoint\nThe primary endpoint is any grade 3 or 4 adverse event (AE) leading to chemotherapy discontinuation up to six months after randomization. AE are assessed by the US National Cancer Institute Common Terminology Criteria for Adverse Events (CTCAE v5).\n\n\n2.2.3 Sample size\nThe sample size was fixed to \\(N_{max}=36\\) patients (24 patients in the experimental arm, 12 patients in the control arm) because of feasibility.\n\n\n2.2.4 Study design\nThe following figure summarises the trial design. Suppose we randomise patients with a 2:1 allocation ratio to the experimental arm and the control arm. Let \\(p_i\\) be the CD proportion coming from a design prior \\(\\pi^d_i \\sim Beta(a^d_i,b^d_i)\\), \\(p_i\\), \\(i=0,1\\). The design prior represents the uncertainty of \\(p_i\\) at the design stage and might be different from the analysis prior. One interim analysis will be performed after the recruitment of \\(N^{I}=n_{0}+n_{1}=18\\) patients (\\(n_{0}\\) denotes the number of patients in the control arm and \\(n_{1}\\) denotes the number of patients in the experimental arm; The index \\(I\\) stands for ‘interim’) which corresponds to 50% of the fixed sample size.\n\n\n\n\n\nflowchart TD\n  A[2:1 randomisation] --&gt; B[Experimental group with CD proportion \\np1 coming from design prior]\n  A --&gt; C[Control group with CD proportion \\np0 coming from design prior]\n  B ~~~ D[Interim analysis\\n\\nStop early:\\nIf experimental group has a high predictive probability of excessive discontinuation\\notherwise randomise new patients until N_max is reached]\n  C ~~~ D\n  style A fill:white,color:black\n  style B fill:white,color:black\n  style C fill:white,color:black\n  style D fill:white,color:black,stroke-dasharray: 5 5\n\n\n\n\n\n\n\n\n2.2.5 Stopping criterium\nThe excessive threshold for stopping the trial was set to \\(p_{max}=0.2\\). This number was based on the design prior choice (see subsection ‘Design prior choice’). In brief, based on a discussion with clinical experts and available evidence the assumed mean average CD proportion was set to \\(0.1\\). A doubling of this number led to \\(p_{max}=0.2\\).\n\n\n2.2.6 Statistical methods\nSuppose that at the interim analysis in the experimental arm \\(r_{1}\\) discontinuation events are observed. If we assume that \\(N_{max}=n_{max, 0}+n_{max, 1}\\) is the planned sample size of the trial, then a remaining future \\(m_{1}=n_{max, 1}-n_{1}\\) will be recruited in the experimental arm with possible future events \\(S_1\\in\\{0,\\cdots, m_1\\}\\). Note that at each interim analysis the posterior distribution is Beta-distributed \\(p_i|r_i,n_i \\sim Beta(a_i+r_i, b_i+n_i-r_i)\\) and \\(S_1|r_1,n_1\\) is Beta-binomial distributed \\(S_1 \\sim Betabinomal(m_1, a+r_1, b+n_1-r_1)\\).\nThe trial is stopped early if \\(PP&gt;\\theta_{S}\\), for an upper discontinuation proportion threshold \\(p_{max}\\), \\[\n\\begin{aligned}\nPP&=E\\left[I\\left\\{ P\\left(p_1&gt;p_{max}|r_{1}, n_{1}, s_{1}\\right)&gt;\\theta_{T_{Non-safe}}\\right\\}|r_{1}, n_{1}\\right] \\\\\n&=\\sum_{s_1=0}^{m_1} I(P(p_1 &gt; p_{max}|r_{1},n_1,s_1)&gt;\\theta_{T_{Non-safe}}) P(S_{1}=s_1|r_{1}, n_1).\n\\end{aligned}\n\\] That is, we stop the trial early if there is a high predictive probability \\(\\Theta_S\\) that the discontinuation proportion in the experimental arm exceeds a upper threshold \\(p_{max}\\) given interim data and future events, otherwise the remaining 18 patients are randomised until the fixed sample size is reached.\nStopping boundaries are calculated for each combination of \\(r_1\\) (and thus \\(m_1\\)) given the maximal sample size \\(N_{max}\\) and the interim sample size \\(N^I\\). The tibble below shows the example of \\(r_1=2\\) and \\(n_1=12\\) for the skeptical prior. We set \\(\\theta_{T_{Non-safe}}=0.6\\).\n\n\nShow R code\np_max &lt;- c(0.2)\n\n# Prior information\nprior_type &lt;- \"Skeptical\"\na_1 &lt;- 2.4\nb_1 &lt;- 9.6\n\nx &lt;- seq(0,1,0.001)\n\nn_initial &lt;- 12\nr &lt;- 0:n_initial\nn_increase &lt;- 12\n\nn_max &lt;- 24\nn &lt;- seq(n_initial, n_max, n_increase)\nr &lt;- 0:n_max\nm &lt;- n_max-r\n\n#### Scenario\ntheta_T &lt;- 0.6\n\n\n\ndata &lt;- expand.grid(n=n, r=r) %&gt;% arrange(n) %&gt;% \n  filter(n&gt;=r) %&gt;% mutate(i=n_max-n+1)\ndata &lt;- expandRows(data, count=3)\ndata &lt;- data %&gt;% group_by(n, r) %&gt;% \n  mutate(m=n_max-n, ind=1, i=cumsum(ind)-1, ind=NULL)\n\ndata &lt;- data %&gt;% \n  mutate(PS1=dbbinom(i, size=m, alpha=a_1+r, beta=b_1+n-r), \n                        Ti=1-pbeta(p_max, a_1+r+i, b_1+n_max-r-i), \n                        ind=ifelse(Ti&gt;theta_T, 1, 0), n_max)\n\ndata &lt;- data %&gt;% select(n_max, n, r, m, i, Ti, PS1, ind)\ndata %&gt;% filter(n==12, r==2)\n\n\n# A tibble: 13 × 8\n# Groups:   n, r [1]\n   n_max     n     r     m     i     Ti         PS1   ind\n   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1    24    12     2    12     0 0.0881 0.139           0\n 2    24    12     2    12     1 0.190  0.241           0\n 3    24    12     2    12     2 0.334  0.241           0\n 4    24    12     2    12     3 0.500  0.180           0\n 5    24    12     2    12     4 0.661  0.109           1\n 6    24    12     2    12     5 0.793  0.0549          1\n 7    24    12     2    12     6 0.887  0.0235          1\n 8    24    12     2    12     7 0.945  0.00852         1\n 9    24    12     2    12     8 0.976  0.00257         1\n10    24    12     2    12     9 0.990  0.000627        1\n11    24    12     2    12    10 0.997  0.000117        1\n12    24    12     2    12    11 0.999  0.0000148       1\n13    24    12     2    12    12 1.00   0.000000971     1\n\n\nThe predictive probabilities for each \\(r_1\\) are (with \\(\\theta_{S}=0.8\\)):\n\n\nShow R code\n## Early stopping using predictive distribution\n\nthreshold_safety &lt;- 0.8\n\ndata_pp &lt;- data %&gt;% group_by(n_max, n, r) %&gt;% summarise(pp=round(sum(PS1*ind),6), \n                                                 stop_pp=ifelse(pp&gt;threshold_safety, 1, 0))\ndata_pp %&gt;% filter(n==12)\n\n\n# A tibble: 13 × 5\n# Groups:   n_max, n [1]\n   n_max     n     r      pp stop_pp\n   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1    24    12     0 0.00552       0\n 2    24    12     1 0.0459        0\n 3    24    12     2 0.199         0\n 4    24    12     3 0.502         0\n 5    24    12     4 0.814         1\n 6    24    12     5 0.971         1\n 7    24    12     6 1             1\n 8    24    12     7 1             1\n 9    24    12     8 1             1\n10    24    12     9 1             1\n11    24    12    10 1             1\n12    24    12    11 1             1\n13    24    12    12 1             1\n\n\nThe same calculation holds for the neutral prior and we get the following stopping boundaries\n\n\nShow R code\nstop_boundaries0 &lt;- data_pp %&gt;% filter(stop_pp==1) %&gt;%\n  group_by(n_max, n) %&gt;% summarise(r=min(r), stop=NULL)\nstop_boundaries0$p_max &lt;- p_max\nstop_boundaries0$theta_T &lt;- theta_T\nstop_boundaries0$threshold_safety &lt;- threshold_safety\nstop_boundaries0$prior_type &lt;- prior_type\nstop_boundaries &lt;- stop_boundaries0\n\n# Prior information\nprior_type &lt;- \"Neutral\"\na_1 &lt;- 0.6\nb_1 &lt;- 5.4\n\nx &lt;- seq(0,1,0.001)\n\nn_initial &lt;- 12\nr &lt;- 0:n_initial\nn_increase &lt;- 12\n\nn_max &lt;- 24\nn &lt;- seq(n_initial, n_max, n_increase)\nr &lt;- 0:n_max\nm &lt;- n_max-r\n\n#### Scenario\ntheta_T &lt;- 0.6\nthreshold_safety &lt;- 0.8\n\n\ndata &lt;- expand.grid(n=n, r=r) %&gt;% arrange(n) %&gt;% filter(n&gt;=r) %&gt;% mutate(i=n_max-n+1)\ndata &lt;- expandRows(data, count=3)\ndata &lt;- data %&gt;% group_by(n, r) %&gt;% mutate(m=n_max-n, ind=1, i=cumsum(ind)-1, ind=NULL)\n\ndata &lt;- data %&gt;% mutate(cond_postprob=dbbinom(i, size=m, alpha=a_1+r, beta=b_1+n-r), \n                        Ti=1-pbeta(p_max, a_1+r+i, b_1+n_max-r-i), \n                        ind=ifelse(Ti&gt;theta_T, 1, 0), n_max)\n\ndata &lt;- data %&gt;% select(n_max, n, r, m, i, cond_postprob, Ti, ind)\n\n\n\n## Early stopping using predictive distribution\ndata_pp &lt;- data %&gt;% group_by(n_max, n, r) %&gt;% summarise(pp=round(sum(cond_postprob*ind),6), \n                                                 stop_pp=ifelse(pp&gt;threshold_safety, 1, 0))\n\n\n\nstop_boundaries0 &lt;- data_pp %&gt;% filter(stop_pp==1) %&gt;%\n  group_by(n_max, n) %&gt;% summarise(r=min(r), stop=NULL)\nstop_boundaries0$p_max &lt;- p_max\nstop_boundaries0$theta_T &lt;- theta_T\nstop_boundaries0$threshold_safety &lt;- threshold_safety\nstop_boundaries0$prior_type &lt;- prior_type\nstop_boundaries &lt;- bind_rows(stop_boundaries, stop_boundaries0)\n\n\nstop_boundaries %&gt;% filter(n==12)\n\n\n# A tibble: 2 × 7\n# Groups:   n_max [1]\n  n_max     n     r p_max theta_T threshold_safety prior_type\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;     \n1    24    12     4   0.2     0.6              0.8 Skeptical \n2    24    12     5   0.2     0.6              0.8 Neutral   \n\n\n\n2.2.6.1 Design prior choice\nThe design prior for the primary endpoint was chosen as based on clinical expert knowledge and available evidence. The TOPAZ-I trial reported 8.9% AE leading to discontinuation, while KENOTE 966 reported a discontinuation proportion of 3%. We decided to be a bit more conservative with an average CD proportion of 10%, while accounting for uncertainty in this assumed proportion: We assumed that the “true” CD proportion comes from a \\(Beta(1.2,10.8)\\) design prior which is centered at a CD proportion of 10% with a 90% uncertainty range from 0.9% to 26.6%. The probability that the discontinuation rate is larger than 20% is 12.2%. The design prior has weight of 12 patients, that is, half of planned patients in the experimental arm.\n\n\n\n\n\n\n\n\n\n\n\n2.2.6.2 Analysis prior choice\nAs analysis priors we decided for two scenarios.\n\nA skeptical Beta(2.4, 9.4) analysis prior for the experimental arm which is centered on a CD proportion of 20% with a probability of excessing 40% of \\(5.6\\)%.\nA neutral Beta(0.6, 5.4) analysis prior for the experimental arm which is centered on a discontinuation proportion of 10%.\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.7 Simulation study\nWe set up simulation study to quantify operations characteristics\n\nProbability of stopping because of non-safety (stopping trial before \\(N_{max}\\) is reached),\nProbability of treatment discontinuation (declaring treatment discontinuation including \\(N_{max}\\)),\nExpected number of patients in experimental arm\n\nwith the following parameters\n\nBeta design priors: Boths arms: a=1.5, b=13.5. True \\(p_i\\) are drawn from the design priors,\nBeta analysis priors: Boths arms: Skeptical: a=2.4, b=9.6. Neutral: a=0.6, b=5.4,\nMaximal discontinuation proportion threshold \\(p_{max}\\): 0.2,\nNumber of randomised patients in the experimental arm at first interim analysis \\(n_1\\): 12,\nNumber of randomised patients in the control arm at first interim analysis \\(n_1\\): 6,\nExcessive discontinuation probability for posterior distribution \\(\\theta_{T}\\): 0.6,\nSafety threshold for predictive distribution \\(\\theta_{S}\\): 0.8,\nNumber of simulation runs: 10’000,\nMaximal sample size \\(N_{max}\\): 12/24 patients per arm,\nIncrease of sample size \\(n_{increase}\\): 6/12 patients per arm.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ABLATIO-BILICA</span>"
    ]
  },
  {
    "objectID": "01-Chapter1.html#study-design",
    "href": "01-Chapter1.html#study-design",
    "title": "2  ABLATIO-BILICA",
    "section": "2.4 Study design",
    "text": "2.4 Study design\nThe following figure summarises the trial design\n\n\n\n\n\n\n\n\n\n\n2.4.1 Statistics\nSuppose we randomise patients with a 2:1 allocation ratio to the experimental arm and the control arm. Let \\(p_i\\) be the true discontinuation proportion and \\(\\pi^d_i \\sim Beta(a^d_i,b^d_i)\\) be a design prior on \\(p_i\\), \\(i=0,1\\). The design prior represents the uncertainty of \\(p_i\\) at the design stage and might be different from the analysis prior. In the following we use the same parameters for the design and analysis prior.\nThe \\(j\\)th interim analysis will be performed after the recruitment of \\(N_j=n_{j,0}+n_{j,1}\\) patients (\\(n_{j,0}\\) denotes the number of patients in the control arm and \\(n_{j,1}\\) denotes the number of patients in the experimental arm). For notational simplicity we skip the index \\(j\\) in the following.\nSuppose that at an interim analysis in the experimental arm \\(r_{1}\\) discontinuation events are observed. If we assume that \\(N_{max}=n_{max, 0}+n_{max, 1}\\) is the planned sample size of the trial, then a remaining future \\(m_{1}=n_{max, 1}-n_{1}\\) will be recruited in the experimental arm with possible future events \\(S_1\\in\\{0,\\cdots, m_1\\}\\). Note that at each interim analysis the posterior distribution is Beta-distributed \\(p_i|r_i,n_i \\sim Beta(a_i+r_i, b_i+n_i-r_i)\\) with mean \\(\\overline{p}_i|r_i,n_i=\\frac{a_i+r_i}{a_i+b_i+n_i}\\).\n\n2.4.1.1 Early stopping rules\nThe trial is stopped early if \\(PP&gt;\\theta_{S}\\), for an upper discontinuation proportion threshold \\(p_{max}\\), \\[\n\\begin{aligned}\nPP&=E\\left[I\\left\\{ P\\left(p_1&gt;p_{max}|r_{1}, n_{1}, s_{1}\\right)&gt;\\theta_{T_{Non-safe}}\\right\\}|r_{1}, n_{1}\\right] \\\\\n&=\\sum_{s_1=0}^{m_1} I(P(p_1 &gt; p_{max}|r_{1},n_1,s_1)&gt;\\theta_{T_{Non-safe}}) P(S_{1}=s_1|r_{1}, n_1).\n\\end{aligned}\n\\] That is, we stop the trial early if there is a high predictive probability \\(\\Theta_S\\) that the discontinuation proportion in the experimental arm exceeds a upper threshold \\(p_{max}\\) given interim data and future events, otherwise \\(n^*\\) new patients are randomised.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ABLATIO-BILICA</span>"
    ]
  },
  {
    "objectID": "01-Chapter1.html#abbreviations",
    "href": "01-Chapter1.html#abbreviations",
    "title": "2  ABLATIO-BILICA",
    "section": "",
    "text": "AE: Adverse event\nbRFA: Biliary intraductal radiofrequency ablation\nCD: Chemotherapy discontinuation\nCICI: Chemo-immune checkpoint inhibitor-therapy\nEBTC: Extrahepatic biliary tract cancer",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ABLATIO-BILICA</span>"
    ]
  },
  {
    "objectID": "01-Chapter1.html#background",
    "href": "01-Chapter1.html#background",
    "title": "2  ABLATIO-BILICA",
    "section": "2.2 Background",
    "text": "2.2 Background\nThe ABLATIO-BILICA trial aims to evaluate the safety of biliary intraductal radiofrequency ablation in patients with unresectable extrahepatic biliary tract cancer (EBTC) undergoing standard of care chemo-immune checkpoint inhibitor-therapy (CICI). It is a phase-II multicenter two-arm randomized controlled study.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ABLATIO-BILICA</span>"
    ]
  },
  {
    "objectID": "01-Chapter1.html#author",
    "href": "01-Chapter1.html#author",
    "title": "2  ABLATIO-BILICA",
    "section": "Author",
    "text": "Author\nAndré Moser, Senior Statistician\nDepartment of Clinical Research\nUniversity of Bern\n3012 Bern, Switzerland\n\n\n\n\n1. Lee JJ, Liu DD. A predictive probability design for phase II cancer clinical trials. Clinical Trials. 2008;5: 93–106. doi:10.1177/1740774508089279\n\n\n2. Sambucini V. Efficacy and toxicity monitoring via bayesian predictive probabilities in phase II clinical trials. Statistical Methods & Applications. 2021;30: 637–663. doi:10.1007/s10260-020-00537-3",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ABLATIO-BILICA</span>"
    ]
  },
  {
    "objectID": "01-Chapter1.html#stopping-boundaries",
    "href": "01-Chapter1.html#stopping-boundaries",
    "title": "2  ABLATIO-BILICA",
    "section": "2.4 Stopping boundaries",
    "text": "2.4 Stopping boundaries\n\n\n# A tibble: 4 × 7\n# Groups:   n_max [1]\n  n_max     n     r p_max theta_T threshold_safety prior_type\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;     \n1    24    12     4   0.2     0.6              0.8 Skeptical \n2    24    24     6   0.2     0.6              0.8 Skeptical \n3    24    12     5   0.2     0.6              0.8 Neutral   \n4    24    24     7   0.2     0.6              0.8 Neutral",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ABLATIO-BILICA</span>"
    ]
  },
  {
    "objectID": "01-Chapter1.html#results",
    "href": "01-Chapter1.html#results",
    "title": "2  ABLATIO-BILICA",
    "section": "2.3 Results",
    "text": "2.3 Results\nThe results from our simulation study are:\n\n\n\n\n\n\n\nOperations characteristics\n\\(N_{max}=36\\)\n\n\n\n\nProbability of intolerable trial (skeptical prior)\n15.8%\n\n\nProbability of intolerable trial (neutral prior)\n8.2%\n\n\nProbability of early stopping because of non-safety\n7.7%\n\n\nExpected number of patients in experimental arm\n23.1\n\n\n\n\n\n\n\n\n\n\nStopping boundaries\n\n\n\n\n\nStopping boundary interim analysis (skeptical prior)\n4+\n\n\nIntolerable trial at trial end (skeptical prior)\n6+\n\n\nIntolerable trial at trial end (neutral prior)\n7+",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ABLATIO-BILICA</span>"
    ]
  },
  {
    "objectID": "02-SampleSize-ContinuousOutcome.html#study-description",
    "href": "02-SampleSize-ContinuousOutcome.html#study-description",
    "title": "3  Two-arm study with a continuous primary outcome",
    "section": "",
    "text": "3.1.1 Primary objective\nThe study examines the impact of a treatment on upper limb motor activity in everyday life.\n\n\n3.1.2 Primary outcome\nThe primary endpoint is bimanual hand function measured with the Assisting Hand Assessment (AHA) after treatment.\n\n\n3.1.3 Study design\nIn this exploratory randomized Bayesian phase-II trial, we evaluate the probability that the investigational treatment is superior to the standard of care using Bayesian statistics. If this probability exceeds 90%, we deem the treatment as promising.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Two-arm study with a continuous primary outcome</span>"
    ]
  },
  {
    "objectID": "02-SampleSize-ContinuousOutcome.html#methods-and-assumptions",
    "href": "02-SampleSize-ContinuousOutcome.html#methods-and-assumptions",
    "title": "3  Two-arm study with a continuous primary outcome",
    "section": "3.2 Methods and assumptions",
    "text": "3.2 Methods and assumptions\nWe calculate the Bayesian probability of success (equivalent to the frequentist power) for the primary outcome using Monte-Carlo simulations. Success is defined as a difference in AHA greater than 0 in favor of the treatment. We simulate outcome and its respective baseline data from a multivariate normal distribution with a correlation of 0.5 and evaluate the treatment difference using Bayesian linear regression. We calculate the probability of success twice, first, using a non-informative prior (i.e. not integrating any prior information) and second, using an informative prior with an effect size of 1.0 and a precision of 1.0, which was based on a previous publication. This prior corresponds to approximately two patients in terms of weight.\n\nAllocation ratio: 1:1\nEffect measure: Difference in AHA (corrected for the baseline value)\nAnalysis approach: Bayesian linear regression using INLA\nExpected effect size: 0.6\nExpected correlation between baseline and outcome value: 0.5\nProbability threshold to claim success: 0.9\nNon-informative prior: Mean 0, precision 0.001\nInformative prior: Mean 1.0, precision 1.0\nTotal sample size: 34\nNumber of simulations: 10,000",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Two-arm study with a continuous primary outcome</span>"
    ]
  },
  {
    "objectID": "02-SampleSize-ContinuousOutcome.html#calculation-using-r",
    "href": "02-SampleSize-ContinuousOutcome.html#calculation-using-r",
    "title": "3  Two-arm study with a continuous primary outcome",
    "section": "3.3 Calculation using R",
    "text": "3.3 Calculation using R\n\n3.3.1 R-code\n\n\nShow R code\n#install.packages(\"C:/download/INLA_24.02.09.zip\", repos = NULL, type = \"bin\") # manual download of latest version\nlibrary(INLA)\nlibrary(MASS)\n\nrm(list = ls())\nset.seed(123)\n\n# Set parameters\nn_simulations &lt;- 10\nn_patients &lt;- 17 # per arm\neffect_size &lt;- 0.6\ncorrelation &lt;- 0.5\nsd &lt;- 1.0\ncor_matrix &lt;- matrix(c(sd, correlation, correlation, sd), nrow = 2)\n\n# Define prior and threshold probability\nsd_p &lt;- 1\nprec_p &lt;- 1/sd_p^2\nmean_p &lt;- 1.0\nprior_custom &lt;- list(mean=list(treatment=mean_p), prec=list(treatment=prec_p))\nthreshold_prob &lt;- 0.9\n\nsuccess_noprior &lt;- numeric(n_simulations)\nsuccess_prior &lt;- numeric(n_simulations)\n\n# Simulate and fit the model multiple times\nfor (i in 1:n_simulations) {\n  print(i)\n  # Generate simulated data\n  control_data &lt;- mvrnorm(n = n_patients, mu = c(0, 0), Sigma = cor_matrix)\n  control_data &lt;- data.frame(\n    baseline = control_data[, 1],\n    outcome = control_data[, 2],\n    treatment = 0\n  )\n  treatment_data &lt;- mvrnorm(n = n_patients, mu = c(0, effect_size), Sigma = cor_matrix)\n  treatment_data &lt;- data.frame(\n    baseline = treatment_data[, 1],\n    outcome = treatment_data[, 2],\n    treatment = 1\n  )\n  data &lt;- rbind(control_data, treatment_data)\n  \n  # Model formula\n  formula &lt;- outcome ~ treatment + baseline  # Model formula\n  \n  # Bayesian INLA model without prior (non-informative)\n  model_noprior &lt;- inla(formula, data = data, family = \"gaussian\")\n  model_noprior$summary.fixed\n  1 - inla.pmarginal(0, model_noprior$marginals.fixed$treatment)\n  \n  # Model with informative prior\n  model_prior &lt;- inla(formula, data = data, family = \"gaussian\", control.fixed=prior_custom)\n  model_prior$summary.fixed\n  1 - inla.pmarginal(0, model_prior$marginals.fixed$treatment)\n  \n  # Posterior of treatment coefficient\n  posterior_prob_noprior &lt;- 1 - inla.pmarginal(0, model_noprior$marginals.fixed$treatment)\n  success_noprior[i] &lt;- posterior_prob_noprior &gt; threshold_prob\n  posterior_prob_prior &lt;- 1 - inla.pmarginal(0, model_prior$marginals.fixed$treatment)\n  success_prior[i] &lt;- posterior_prob_prior &gt; threshold_prob\n  }\n  \n# Calculate probability of success\nprob_success_noprior &lt;- mean(success_noprior)\nprob_success_power_prior &lt;- mean(success_prior)\n\n\n\n\n3.3.2 Result of simulation\nThe probability of success based on the non-informative and informative prior is 0.77 and 0.84, respectively.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Two-arm study with a continuous primary outcome</span>"
    ]
  },
  {
    "objectID": "02-SampleSize-ContinuousOutcome.html#analysis-approach",
    "href": "02-SampleSize-ContinuousOutcome.html#analysis-approach",
    "title": "3  Two-arm study with a continuous primary outcome",
    "section": "3.4 Analysis approach",
    "text": "3.4 Analysis approach\nThe primary outcome will be assessed in both groups before and after the training. The difference in AHA between groups will be evaluated using a Bayesian linear regression model, adjusting for baseline values and stratification factors employed during randomization. An informative Gaussian prior, as described in the sample size section above, will be incorporated into the model. From the posterior distribution, we will calculate the mean difference along with a 95% credible interval as well as the probability that investigational treatment is superior to standard of care. In a sensitivity analysis, a non-informative prior will be employed.\n\nAuthor\nAndreas Limacher, PhD\nDepartment of Clinical Research\nUniversity of Bern\n3012 Bern, Switzerland",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Two-arm study with a continuous primary outcome</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-BinaryOutcome.html",
    "href": "01-SampleSize-BinaryOutcome.html",
    "title": "1  Two-arm study with a binary primary outcome for assessing threshold stopping",
    "section": "",
    "text": "1.1 Methods",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Two-arm study with a binary primary outcome for assessing threshold stopping</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-BinaryOutcome.html#methods",
    "href": "01-SampleSize-BinaryOutcome.html#methods",
    "title": "1  Two-arm study with a binary primary outcome for assessing threshold stopping",
    "section": "",
    "text": "1.1.1 Sample size\nThe sample size was fixed to \\(N_{max}=36\\) patients (24 patients in the experimental arm, 12 patients in the control arm) because of feasibility.\n\n\n1.1.2 Study design\nThe following figure summarises the trial design. Suppose we randomise patients with a 2:1 allocation ratio to the experimental arm and the control arm. Let \\(p_i\\) be the TD proportion coming from a design prior \\(\\pi^d_i \\sim Beta(a^d_i,b^d_i)\\), \\(p_i\\), \\(i=0,1\\). The design prior represents the uncertainty of \\(p_i\\) at the design stage and might be different from the analysis prior. One interim analysis will be performed after the recruitment of \\(N^{I}=n_{0}+n_{1}=18\\) patients (\\(n_{0}\\) denotes the number of patients in the control arm and \\(n_{1}\\) denotes the number of patients in the experimental arm; The index \\(I\\) stands for ‘interim’) which corresponds to 50% of the fixed sample size.\n\n\n\n\n\nflowchart TD\n  A[2:1 randomisation] --&gt; B[Experimental group with TD proportion \\np1 coming from design prior]\n  A --&gt; C[Control group with TD proportion \\np0 coming from design prior]\n  B ~~~ D[Interim analysis\\n\\nStop early:\\nIf experimental group has a high predictive probability of excessive discontinuation\\notherwise randomise new patients until N_max is reached]\n  C ~~~ D\n  style A fill:white,color:black\n  style B fill:white,color:black\n  style C fill:white,color:black\n  style D fill:white,color:black,stroke-dasharray: 5 5\n\n\n\n\n\n\n\n\n1.1.3 Stopping criterium\nThe excessive threshold for stopping the trial was set to \\(p_{max}=0.2\\). This number was based on the design prior choice (see subsection ‘Design prior choice’). In brief, based on a discussion with clinical experts and available evidence the assumed mean average TD proportion was set to \\(0.1\\). A doubling of this number led to \\(p_{max}=0.2\\).\n\n\n1.1.4 Statistical methods\nSuppose that at the interim analysis in the experimental arm \\(r_{1}\\) discontinuation events are observed. If we assume that \\(N_{max}=n_{max, 0}+n_{max, 1}\\) is the planned sample size of the trial, then a remaining future \\(m_{1}=n_{max, 1}-n_{1}\\) will be recruited in the experimental arm with possible future events \\(S_1\\in\\{0,\\cdots, m_1\\}\\). Note that at each interim analysis the posterior distribution is Beta-distributed \\(p_i|r_i,n_i \\sim Beta(a_i+r_i, b_i+n_i-r_i)\\) and \\(S_1|r_1,n_1\\) is Beta-binomial distributed \\(S_1 \\sim Betabinomal(m_1, a+r_1, b+n_1-r_1)\\).\nThe trial is stopped early if \\(PP&gt;\\theta_{S}\\), for an upper discontinuation proportion threshold \\(p_{max}\\), \\[\n\\begin{aligned}\nPP&=E\\left[I\\left\\{ P\\left(p_1&gt;p_{max}|r_{1}, n_{1}, s_{1}\\right)&gt;\\theta_{T_{Non-safe}}\\right\\}|r_{1}, n_{1}\\right] \\\\\n&=\\sum_{s_1=0}^{m_1} I(P(p_1 &gt; p_{max}|r_{1},n_1,s_1)&gt;\\theta_{T_{Non-safe}}) P(S_{1}=s_1|r_{1}, n_1).\n\\end{aligned}\n\\] That is, we stop the trial early if there is a high predictive probability \\(\\Theta_S\\) that the discontinuation proportion in the experimental arm exceeds a upper threshold \\(p_{max}\\) given interim data and future events, otherwise the remaining 18 patients are randomised until the fixed sample size is reached.\nStopping boundaries are calculated for each combination of \\(r_1\\) (and thus \\(m_1\\)) given the maximal sample size \\(N_{max}\\) and the interim sample size \\(N^I\\). The tibble below shows the example of \\(r_1=2\\) and \\(n_1=12\\) for the skeptical prior. We set \\(\\theta_{T_{Non-safe}}=0.6\\).\n\n\nShow R code\np_max &lt;- c(0.2)\n\n# Prior information\nprior_type &lt;- \"Skeptical\"\na_1 &lt;- 2.4\nb_1 &lt;- 9.6\n\nx &lt;- seq(0,1,0.001)\n\nn_initial &lt;- 12\nr &lt;- 0:n_initial\nn_increase &lt;- 12\n\nn_max &lt;- 24\nn &lt;- seq(n_initial, n_max, n_increase)\nr &lt;- 0:n_max\nm &lt;- n_max-r\n\n#### Scenario\ntheta_T &lt;- 0.6\n\n\n\ndata &lt;- expand.grid(n=n, r=r) %&gt;% arrange(n) %&gt;% \n  filter(n&gt;=r) %&gt;% mutate(i=n_max-n+1)\ndata &lt;- expandRows(data, count=3)\ndata &lt;- data %&gt;% group_by(n, r) %&gt;% \n  mutate(m=n_max-n, ind=1, i=cumsum(ind)-1, ind=NULL)\n\ndata &lt;- data %&gt;% \n  mutate(PS1=dbbinom(i, size=m, alpha=a_1+r, beta=b_1+n-r), \n                        Ti=1-pbeta(p_max, a_1+r+i, b_1+n_max-r-i), \n                        ind=ifelse(Ti&gt;theta_T, 1, 0), n_max)\n\ndata &lt;- data %&gt;% select(n_max, n, r, m, i, Ti, PS1, ind)\ndata %&gt;% filter(n==12, r==2)\n\n\n# A tibble: 13 × 8\n# Groups:   n, r [1]\n   n_max     n     r     m     i     Ti         PS1   ind\n   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1    24    12     2    12     0 0.0881 0.139           0\n 2    24    12     2    12     1 0.190  0.241           0\n 3    24    12     2    12     2 0.334  0.241           0\n 4    24    12     2    12     3 0.500  0.180           0\n 5    24    12     2    12     4 0.661  0.109           1\n 6    24    12     2    12     5 0.793  0.0549          1\n 7    24    12     2    12     6 0.887  0.0235          1\n 8    24    12     2    12     7 0.945  0.00852         1\n 9    24    12     2    12     8 0.976  0.00257         1\n10    24    12     2    12     9 0.990  0.000627        1\n11    24    12     2    12    10 0.997  0.000117        1\n12    24    12     2    12    11 0.999  0.0000148       1\n13    24    12     2    12    12 1.00   0.000000971     1\n\n\nThe predictive probabilities for each \\(r_1\\) are (with \\(\\theta_{S}=0.8\\)):\n\n\nShow R code\n## Early stopping using predictive distribution\n\nthreshold_safety &lt;- 0.8\n\ndata_pp &lt;- data %&gt;% group_by(n_max, n, r) %&gt;% summarise(pp=round(sum(PS1*ind),6), \n                                                 stop_pp=ifelse(pp&gt;threshold_safety, 1, 0))\ndata_pp %&gt;% filter(n==12)\n\n\n# A tibble: 13 × 5\n# Groups:   n_max, n [1]\n   n_max     n     r      pp stop_pp\n   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1    24    12     0 0.00552       0\n 2    24    12     1 0.0459        0\n 3    24    12     2 0.199         0\n 4    24    12     3 0.502         0\n 5    24    12     4 0.814         1\n 6    24    12     5 0.971         1\n 7    24    12     6 1             1\n 8    24    12     7 1             1\n 9    24    12     8 1             1\n10    24    12     9 1             1\n11    24    12    10 1             1\n12    24    12    11 1             1\n13    24    12    12 1             1\n\n\nThe same calculation holds for the neutral prior and we get the following stopping boundaries\n\n\nShow R code\nstop_boundaries0 &lt;- data_pp %&gt;% filter(stop_pp==1) %&gt;%\n  group_by(n_max, n) %&gt;% summarise(r=min(r), stop=NULL)\nstop_boundaries0$p_max &lt;- p_max\nstop_boundaries0$theta_T &lt;- theta_T\nstop_boundaries0$threshold_safety &lt;- threshold_safety\nstop_boundaries0$prior_type &lt;- prior_type\nstop_boundaries &lt;- stop_boundaries0\n\n# Prior information\nprior_type &lt;- \"Neutral\"\na_1 &lt;- 0.6\nb_1 &lt;- 5.4\n\nx &lt;- seq(0,1,0.001)\n\nn_initial &lt;- 12\nr &lt;- 0:n_initial\nn_increase &lt;- 12\n\nn_max &lt;- 24\nn &lt;- seq(n_initial, n_max, n_increase)\nr &lt;- 0:n_max\nm &lt;- n_max-r\n\n#### Scenario\ntheta_T &lt;- 0.6\nthreshold_safety &lt;- 0.8\n\n\ndata &lt;- expand.grid(n=n, r=r) %&gt;% arrange(n) %&gt;% filter(n&gt;=r) %&gt;% mutate(i=n_max-n+1)\ndata &lt;- expandRows(data, count=3)\ndata &lt;- data %&gt;% group_by(n, r) %&gt;% mutate(m=n_max-n, ind=1, i=cumsum(ind)-1, ind=NULL)\n\ndata &lt;- data %&gt;% mutate(cond_postprob=dbbinom(i, size=m, alpha=a_1+r, beta=b_1+n-r), \n                        Ti=1-pbeta(p_max, a_1+r+i, b_1+n_max-r-i), \n                        ind=ifelse(Ti&gt;theta_T, 1, 0), n_max)\n\ndata &lt;- data %&gt;% select(n_max, n, r, m, i, cond_postprob, Ti, ind)\n\n\n\n## Early stopping using predictive distribution\ndata_pp &lt;- data %&gt;% group_by(n_max, n, r) %&gt;% summarise(pp=round(sum(cond_postprob*ind),6), \n                                                 stop_pp=ifelse(pp&gt;threshold_safety, 1, 0))\n\n\n\nstop_boundaries0 &lt;- data_pp %&gt;% filter(stop_pp==1) %&gt;%\n  group_by(n_max, n) %&gt;% summarise(r=min(r), stop=NULL)\nstop_boundaries0$p_max &lt;- p_max\nstop_boundaries0$theta_T &lt;- theta_T\nstop_boundaries0$threshold_safety &lt;- threshold_safety\nstop_boundaries0$prior_type &lt;- prior_type\nstop_boundaries &lt;- bind_rows(stop_boundaries, stop_boundaries0)\n\n\nstop_boundaries %&gt;% filter(n==12)\n\n\n# A tibble: 2 × 7\n# Groups:   n_max [1]\n  n_max     n     r p_max theta_T threshold_safety prior_type\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;     \n1    24    12     4   0.2     0.6              0.8 Skeptical \n2    24    12     5   0.2     0.6              0.8 Neutral   \n\n\n\n1.1.4.1 Design prior choice\nThe design prior for the primary endpoint was chosen as based on clinical expert knowledge and available evidence. We assumed that the “true” TD proportion comes from a \\(Beta(1.2,10.8)\\) design prior which is centered at a TD proportion of 10% with a 90% uncertainty range from 0.9% to 26.6%. The probability that the discontinuation rate is larger than 20% is 12.2%. The design prior has weight of 12 patients, that is, half of planned patients in the experimental arm.\n\n\n\n\n\n\n\n\n\n\n\n1.1.4.2 Analysis prior choice\nAs analysis priors we decided for two scenarios.\n\nA skeptical Beta(2.4, 9.4) analysis prior for the experimental arm which is centered on a TD proportion of 20% with a probability of excessing 40% of \\(5.6\\)%.\nA neutral Beta(0.6, 5.4) analysis prior for the experimental arm which is centered on a discontinuation proportion of 10%.\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.1.5 Simulation study\nWe set up simulation study to quantify operations characteristics\n\nProbability of stopping because of non-safety (stopping trial before \\(N_{max}\\) is reached),\nProbability of treatment discontinuation (declaring treatment discontinuation including \\(N_{max}\\)),\nExpected number of patients in experimental arm\n\nwith the following parameters\n\nBeta design priors: Boths arms: a=1.5, b=13.5. True \\(p_i\\) are drawn from the design priors,\nBeta analysis priors: Boths arms: Skeptical: a=2.4, b=9.6. Neutral: a=0.6, b=5.4,\nMaximal discontinuation proportion threshold \\(p_{max}\\): 0.2,\nNumber of randomised patients in the experimental arm at first interim analysis \\(n_1\\): 12,\nNumber of randomised patients in the control arm at first interim analysis \\(n_1\\): 6,\nExcessive discontinuation probability for posterior distribution \\(\\theta_{T}\\): 0.6,\nSafety threshold for predictive distribution \\(\\theta_{S}\\): 0.8,\nNumber of simulation runs: 10’000,\nMaximal sample size \\(N_{max}\\): 12/24 patients per arm,\nIncrease of sample size \\(n_{increase}\\): 6/12 patients per arm.",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Two-arm study with a binary primary outcome for assessing threshold stopping</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-BinaryOutcome.html#results",
    "href": "01-SampleSize-BinaryOutcome.html#results",
    "title": "1  Two-arm study with a binary primary outcome for assessing threshold stopping",
    "section": "1.2 Results",
    "text": "1.2 Results\nThe results from our simulation study are:\n\n\n\n\n\n\n\nOperations characteristics\n\\(N_{max}=36\\)\n\n\n\n\nProbability of intolerable trial (skeptical prior)\n15.8%\n\n\nProbability of intolerable trial (neutral prior)\n8.2%\n\n\nProbability of early stopping because of non-safety\n7.7%\n\n\nExpected number of patients in experimental arm\n23.1\n\n\n\n\n\n\n\n\n\n\nStopping boundaries\n\n\n\n\n\nStopping boundary interim analysis (skeptical prior)\n4+\n\n\nIntolerable trial at trial end (skeptical prior)\n6+\n\n\nIntolerable trial at trial end (neutral prior)\n7+",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Two-arm study with a binary primary outcome for assessing threshold stopping</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-BinaryOutcome.html#author",
    "href": "01-SampleSize-BinaryOutcome.html#author",
    "title": "1  Two-arm study with a binary primary outcome for assessing threshold stopping",
    "section": "Author",
    "text": "Author\nAndré Moser, Senior Statistician\nDepartment of Clinical Research\nUniversity of Bern\n3012 Bern, Switzerland\n\n\n\n\n1. Lee JJ, Liu DD. A predictive probability design for phase II cancer clinical trials. Clinical Trials. 2008;5: 93–106. doi:10.1177/1740774508089279\n\n\n2. Sambucini V. Efficacy and toxicity monitoring via bayesian predictive probabilities in phase II clinical trials. Statistical Methods & Applications. 2021;30: 637–663. doi:10.1007/s10260-020-00537-3",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Two-arm study with a binary primary outcome for assessing threshold stopping</span>"
    ]
  },
  {
    "objectID": "02-SampleSize-ContinuousOutcome.html",
    "href": "02-SampleSize-ContinuousOutcome.html",
    "title": "3  Two-arm study with a continuous primary outcome",
    "section": "",
    "text": "3.1 Study description",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Two-arm study with a continuous primary outcome</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-ContinuousOutcome.html",
    "href": "01-SampleSize-ContinuousOutcome.html",
    "title": "2  Two-arm study with a continuous primary outcome",
    "section": "",
    "text": "2.1 Study description",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Two-arm study with a continuous primary outcome</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-ContinuousOutcome.html#study-description",
    "href": "01-SampleSize-ContinuousOutcome.html#study-description",
    "title": "2  Two-arm study with a continuous primary outcome",
    "section": "",
    "text": "2.1.1 Primary objective\nThe study examines the impact of a treatment on upper limb motor activity in everyday life.\n\n\n2.1.2 Primary outcome\nThe primary endpoint is bimanual hand function measured with the Assisting Hand Assessment (AHA) after treatment.\n\n\n2.1.3 Study design\nIn this exploratory randomized Bayesian phase-II trial, we evaluate the probability that the investigational treatment is superior to the standard of care using Bayesian statistics. If this probability exceeds 90%, we deem the treatment as promising.",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Two-arm study with a continuous primary outcome</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-ContinuousOutcome.html#methods-and-assumptions",
    "href": "01-SampleSize-ContinuousOutcome.html#methods-and-assumptions",
    "title": "2  Two-arm study with a continuous primary outcome",
    "section": "2.2 Methods and assumptions",
    "text": "2.2 Methods and assumptions\nWe calculate the Bayesian probability of success (equivalent to the frequentist power) for the primary outcome using Monte-Carlo simulations. Success is defined as a difference in AHA greater than 0 in favor of the treatment. We simulate outcome and its respective baseline data from a multivariate normal distribution with a correlation of 0.5 and evaluate the treatment difference using Bayesian linear regression. We calculate the probability of success twice, first, using a non-informative prior (i.e. not integrating any prior information) and second, using an informative prior with an effect size of 1.0 and a precision of 1.0, which was based on a previous publication. This prior corresponds to approximately two patients in terms of weight.\n\nAllocation ratio: 1:1\nEffect measure: Difference in AHA (corrected for the baseline value)\nAnalysis approach: Bayesian linear regression using INLA\nExpected effect size: 0.6\nExpected correlation between baseline and outcome value: 0.5\nProbability threshold to claim success: 0.9\nNon-informative prior: Mean 0, precision 0.001\nInformative prior: Mean 1.0, precision 1.0\nTotal sample size: 34\nNumber of simulations: 10,000",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Two-arm study with a continuous primary outcome</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-ContinuousOutcome.html#calculation-using-r",
    "href": "01-SampleSize-ContinuousOutcome.html#calculation-using-r",
    "title": "2  Two-arm study with a continuous primary outcome",
    "section": "2.3 Calculation using R",
    "text": "2.3 Calculation using R\n\n2.3.1 R-code\n\n\nShow R code\n#install.packages(\"C:/download/INLA_24.02.09.zip\", repos = NULL, type = \"bin\") # manual download of latest version\nlibrary(INLA)\nlibrary(MASS)\n\nrm(list = ls())\nset.seed(123)\n\n# Set parameters\nn_simulations &lt;- 10\nn_patients &lt;- 17 # per arm\neffect_size &lt;- 0.6\ncorrelation &lt;- 0.5\nsd &lt;- 1.0\ncor_matrix &lt;- matrix(c(sd, correlation, correlation, sd), nrow = 2)\n\n# Define prior and threshold probability\nsd_p &lt;- 1\nprec_p &lt;- 1/sd_p^2\nmean_p &lt;- 1.0\nprior_custom &lt;- list(mean=list(treatment=mean_p), prec=list(treatment=prec_p))\nthreshold_prob &lt;- 0.9\n\nsuccess_noprior &lt;- numeric(n_simulations)\nsuccess_prior &lt;- numeric(n_simulations)\n\n# Simulate and fit the model multiple times\nfor (i in 1:n_simulations) {\n  print(i)\n  # Generate simulated data\n  control_data &lt;- mvrnorm(n = n_patients, mu = c(0, 0), Sigma = cor_matrix)\n  control_data &lt;- data.frame(\n    baseline = control_data[, 1],\n    outcome = control_data[, 2],\n    treatment = 0\n  )\n  treatment_data &lt;- mvrnorm(n = n_patients, mu = c(0, effect_size), Sigma = cor_matrix)\n  treatment_data &lt;- data.frame(\n    baseline = treatment_data[, 1],\n    outcome = treatment_data[, 2],\n    treatment = 1\n  )\n  data &lt;- rbind(control_data, treatment_data)\n  \n  # Model formula\n  formula &lt;- outcome ~ treatment + baseline  # Model formula\n  \n  # Bayesian INLA model without prior (non-informative)\n  model_noprior &lt;- inla(formula, data = data, family = \"gaussian\")\n  model_noprior$summary.fixed\n  1 - inla.pmarginal(0, model_noprior$marginals.fixed$treatment)\n  \n  # Model with informative prior\n  model_prior &lt;- inla(formula, data = data, family = \"gaussian\", control.fixed=prior_custom)\n  model_prior$summary.fixed\n  1 - inla.pmarginal(0, model_prior$marginals.fixed$treatment)\n  \n  # Posterior of treatment coefficient\n  posterior_prob_noprior &lt;- 1 - inla.pmarginal(0, model_noprior$marginals.fixed$treatment)\n  success_noprior[i] &lt;- posterior_prob_noprior &gt; threshold_prob\n  posterior_prob_prior &lt;- 1 - inla.pmarginal(0, model_prior$marginals.fixed$treatment)\n  success_prior[i] &lt;- posterior_prob_prior &gt; threshold_prob\n  }\n  \n# Calculate probability of success\nprob_success_noprior &lt;- mean(success_noprior)\nprob_success_power_prior &lt;- mean(success_prior)\n\n\n\n\n2.3.2 Result of simulation\nThe probability of success based on the non-informative and informative prior is 0.77 and 0.84, respectively.",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Two-arm study with a continuous primary outcome</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-ContinuousOutcome.html#analysis-approach",
    "href": "01-SampleSize-ContinuousOutcome.html#analysis-approach",
    "title": "2  Two-arm study with a continuous primary outcome",
    "section": "2.4 Analysis approach",
    "text": "2.4 Analysis approach\nThe primary outcome will be assessed in both groups before and after the training. The difference in AHA between groups will be evaluated using a Bayesian linear regression model, adjusting for baseline values and stratification factors employed during randomization. An informative Gaussian prior, as described in the sample size section above, will be incorporated into the model. From the posterior distribution, we will calculate the mean difference along with a 95% credible interval as well as the probability that investigational treatment is superior to standard of care. In a sensitivity analysis, a non-informative prior will be employed.\n\nAuthor\nAndreas Limacher, PhD\nDepartment of Clinical Research\nUniversity of Bern\n3012 Bern, Switzerland",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Two-arm study with a continuous primary outcome</span>"
    ]
  },
  {
    "objectID": "01-SampleSize.html",
    "href": "01-SampleSize.html",
    "title": "Sample size and power",
    "section": "",
    "text": "This section covers specific examples related to the topic of ‘sample size’ and power calculations using either specific designs or endpoints.",
    "crumbs": [
      "Sample size and power"
    ]
  },
  {
    "objectID": "01-SampleSize_Bayesian_power_basics_examples.html",
    "href": "01-SampleSize_Bayesian_power_basics_examples.html",
    "title": "4  External resources and references",
    "section": "",
    "text": "4.1 Peer-reviewed articles",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>External resources and references</span>"
    ]
  },
  {
    "objectID": "01-SampleSize_Bayesian_power_basics_examples.html#peer-reviewed-articles",
    "href": "01-SampleSize_Bayesian_power_basics_examples.html#peer-reviewed-articles",
    "title": "4  External resources and references",
    "section": "",
    "text": "A Review of Bayesian Perspectives on Sample Size Derivation for Confirmatory Trials (2021).\nhttps://pubmed.ncbi.nlm.nih.gov/34992303/\nBayesian sample size determination for diagnostic accuracy studies (2022).\nhttps://onlinelibrary.wiley.com/doi/10.1002/sim.9393\nBayesian estimation supersedes the t test (2013).\nhttps://psycnet.apa.org/doiLanding?doi=10.1037%2Fa0029146\nThe Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective (2017) https://link.springer.com/article/10.3758/s13423-016-1221-4\nBayesian and mixed bayesian/likelihood criteria for sample size determination https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1097-0258(19970415)16:7%3C769::AID-SIM495%3E3.0.CO;2-V",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>External resources and references</span>"
    ]
  },
  {
    "objectID": "01-SampleSize_Bayesian_power_basics_examples.html#blog-posts",
    "href": "01-SampleSize_Bayesian_power_basics_examples.html#blog-posts",
    "title": "4  External resources and references",
    "section": "4.2 Blog posts",
    "text": "4.2 Blog posts\n\nIntroduction to bayesian clinical trial designs (detailed - including R code examples)\nhttps://hbiostat.org/bayes/bet/design\nIntroduction to bayesian sample size calculation (including R code example) https://www.rdatagen.net/post/2021-06-01-bayesian-power-analysis/\nIntroduction to bayesian “power” and comparison with frequentist approaches (including R code example):\nhttps://solomonkurz.netlify.app/blog/bayesian-power-analysis-part-i/ https://solomonkurz.netlify.app/blog/bayesian-power-analysis-part-ii/\nBrief introduction to bayesian power - including comparison with frequentist terms:\nhttps://anatomisebiostats.com/biostatistics-blog/bayesian-sample-size-estimation-in-clinical-study-design-rtcs/\nStopping rules using bayesian analyses https://statmodeling.stat.columbia.edu/2014/02/13/stopping-rules-bayesian-analysis/ http://varianceexplained.org/r/bayesian-ab-testing/",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>External resources and references</span>"
    ]
  },
  {
    "objectID": "01-SampleSize_Bayesian_power_basics_examples.html#r-packages-and-online-tools",
    "href": "01-SampleSize_Bayesian_power_basics_examples.html#r-packages-and-online-tools",
    "title": "4  External resources and references",
    "section": "4.3 R packages and online tools",
    "text": "4.3 R packages and online tools\n\nPackage ‘SampleSizeProportions’ (2023)\nCalculating Sample Size Requirements when Estimating the Difference Between Two Binomial Proportions https://cran.rstudio.com/web/packages/SampleSizeProportions/index.html\nPackage ‘BayesPPD’ (2021)\nBayesian sample size determination using the power and normalized power prior for generalized linear models https://rdrr.io/cran/BayesPPD/man/BayesPPD-package.html\nPackage ‘BayesPPDSurv’ (2024)\nBayesian power/type I error calculation and model fitting using the power prior and the normalized power prior for proportional hazards models with piecewise constant hazard. https://cran.r-project.org/web/packages/BayesPPDSurv/index.html\nPackage ‘BayesCTDesign’ (2021)\nTwo Arm Bayesian Clinical Trial Design with and Without Historical Control Data https://cran.r-project.org/web/packages/BayesCTDesign/index.html\nPackage ‘BayesFactor’ (2024)\nA suite of functions for computing various Bayes factors for simple designs, including contingency tables, one- and two-sample designs, one-way designs, general ANOVA designs, and linear regression. https://cran.r-project.org/web/packages/BayesFactor/index.html\ntrialdesign.org\nAn online resource platform for several phase-I and phase-II designs. https://www.trialdesign.org",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>External resources and references</span>"
    ]
  },
  {
    "objectID": "01-SampleSize_Bayesian_power_basics_examples.html#author",
    "href": "01-SampleSize_Bayesian_power_basics_examples.html#author",
    "title": "4  External resources and references",
    "section": "Author",
    "text": "Author\nSylvain Losdat, PhD\nDepartment of Clinical Research\nUniversity of Bern\n3012 Bern, Switzerland",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>External resources and references</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-Seamless.html",
    "href": "01-SampleSize-Seamless.html",
    "title": "3  Seamless phase-II/III study",
    "section": "",
    "text": "3.1 Available evidence\nFor the control arm we used information from a published randomized controlled trial. The authors reported from approximately 350 total randomized patients to a control arm a disease-free survival percentage of approximately 50% at 24-months. For our sample size calculation we assumed a slightly more conservative percentage of 45%.\nFor the experimental arm we use information from another study with a similar intervention which reported an approximate 70% progression-free survival at 24 months. We assumed a more conservative 60% progression-free survival at 24-months in the experimental arm.\nFor adverse events outcomes (defined by grade 3 CTCAE) in the experimental arm we used the reported number of a review from 20 (4 prospective studies and 16 retrospective studies). For the prospective studies the authors reported a weighted average of 13.9% adverse events, whereas for the retrospective studies a value of 10.4%. We used a slightly more conservative value of 15% for the sample size calculation.\nNo assumptions for the correlation between adverse events and disease-free survival were reported. In our used simulation approach we assumed correlations of 0.1, 0.5 and 0.9 between the adverse event outcome and the progression-free survival.",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Seamless phase-II/III study</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-Seamless.html#author",
    "href": "01-SampleSize-Seamless.html#author",
    "title": "3  Seamless phase-II/III study",
    "section": "Author",
    "text": "Author\nAndré Moser, Senior Statistician\nIulia-Maia Muresan, Statistician\nDepartment of Clinical Research\nUniversity of Bern\n3012 Bern, Switzerland\n\n\n\n\n1. Spiegelhalter DJ, Abrams KR, Myles JP. Bayesian approaches to clinical trials and health‐care evaluation. Wiley; 2003. doi:10.1002/0470092602",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Seamless phase-II/III study</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-Seamless.html#methods",
    "href": "01-SampleSize-Seamless.html#methods",
    "title": "3  Seamless phase-II/III study",
    "section": "3.5 Methods",
    "text": "3.5 Methods\n\n3.5.1 Gaussian approximation\nWe approximate the log hazard ratio of disease-free survival by \\[\n\\theta=log(HR)=\\frac{log(s_1)}{log(s_0)}\n\\] where \\(s_1\\) is the disease-free survival probability of the experimental arm and \\(s_0\\) is the disease-free survival probability of the control arm. In our case we have \\(s_1=0.6\\) and \\(s_0=0.45\\) leading to a \\(log(HR)=0.64\\).\nWe approximate the variance of \\(\\theta\\) with \\(4/m\\), where \\(m\\) is the number of events (see [1], chapter 2.4.2).\n\n\n3.5.2 Phase-II part\nWe plan the phase-II part with an a priori fixed sample size of 100 patients. A safety interim analysis is planned after 25 patients are recruited in the experimental arm.\n\n\n3.5.3 Early stopping phase-II\nWe plan an safety interim analysis which assess’ the probability for an excess adverse event proportion using a Bayesian predictive probability in the experimental arm.\nThe trial is stopped early if \\(PP&gt;\\theta_{S}\\), for an upper discontinuation proportion threshold \\(p_{max}\\), \\[\n\\begin{aligned}\nPP&=E\\left[I\\left\\{ P\\left(p_1&gt;p_{max}|r_{1}, n_{1}, s_{1}\\right)&gt;\\theta_{T_{Non-safe}}\\right\\}|r_{1}, n_{1}\\right] \\\\\n&=\\sum_{s_1=0}^{m_1} I(P(p_1 &gt; p_{max}|r_{1},n_1,s_1)&gt;\\theta_{T_{Non-safe}}) P(S_{1}=s_1|r_{1}, n_1),\n\\end{aligned}\n\\] where \\(r_1\\) (number of observed adverse events at interim analysis), \\(n_1\\) (number of patients at interim analysis), \\(s_1\\) (expected future events at interim analysis) and a threshold \\(\\theta_{T_{Non-safe}}\\).\nIf at this stage the trial is considered as non-safe we stop the trial. Otherwise we recruit more patients until the planned sample size is reached.\n\n\n3.5.4 Decision for phase-III\nThe decision to continue seamlessly into a phase-III trial is based on two criteria\n\n\nWe stop the trial at the end of phase-II part if there is a high probability for excess adverse events (same as described above).\n\n\nIf we have a low predictive probability for a successful phase-III trial at the end of phase-II.\n\n\nFor the latter approach we use a Bayesian predictive ‘interim monitoring’ approach as described in [1], chapter 6.6.3. In brief, we use the observed data at the end of phase-II (interim data \\(y_m\\)), the prior information and the assumed number of ‘future’ phase-III patients (\\(Y_n\\)) to calculate the predictive probability of \\(P(\\theta&lt;0|y_m, Y_n)\\). We stop the trial for futility if \\(P(\\theta&lt;0|y_m, Y_n)&lt;\\epsilon_{fut}\\), which is\n\\[\n1-\\Phi\\left[ \\frac{\\sqrt{m_{phase3}}\\theta_{phase3}}{2}+\\frac{m_{phase2}\\theta_{phase2}}{2\\sqrt{m_{phase3}}}+\\frac{m_{prior}\\theta_{prior}}{2\\sqrt{m_{phase3}}}+\\sqrt{\\frac{m_{prior}+m_{phase2}+m_{phase3}}{m_{phase3}}}\\cdot z_{1-\\epsilon_{fut}} \\right],\n\\] where \\(z_{1-\\epsilon_{fut}}\\) is the upper \\(1-\\epsilon_{fut}\\)%-quantile of a Gaussian distribution.\nThe trial at the end of phase-III is considered as successful if the posterior distribution of the log hazard ratio \\(P(\\theta&lt;0|\\theta_0, y_m, Y)\\geq 1-\\epsilon_{success}\\).\n\n\n3.5.5 Simulation assumptions\nWe assumed bivariate exponentially distributed time to event outcomes for adverse events and disease-free survival. We used the following componentwise rate parameters\n\n\n\n\n\n\n\nParameter\nValue\n\n\n\n\nExponential rate parameter for time to disease progression or death (control arm)\n1/30\n\n\nExponential rate parameter for time to disease progression or death (experimental arm)\n1/47\n\n\nExponential rate parameter for adverse events (experimental arm)\n1/37\n\n\n\nfor simulating data. Based on these parameters we get the proportion of disease progression or death at 24-months in the control arm of\n\n\nShow R code\nrate_event_0 &lt;- 1/30\n\n# Proportion of patients with disease progression or death in control arm at 24-months \npaste0(round(pexp(24, rate_event_0)*100, 0), \"%\")\n\n\n[1] \"55%\"\n\n\nand in the experimental arm of\n\n\nShow R code\nrate_event_1 &lt;- 1/47\n\n# Proportion of patients with disease progression or death in experimental arm at 24-months \npaste0(round(pexp(24, rate_event_1)*100, 0), \"%\")\n\n\n[1] \"40%\"\n\n\nand the proportion of adverse events at 6-months in the experimental arm of\n\n\nShow R code\nrate_tox_1 &lt;- 1/47\n\n# Proportion of patients with disease progression or death in experimental arm at 6-months \npaste0(round(pexp(6, rate_tox_1)*100, 0), \"%\")\n\n\n[1] \"12%\"\n\n\nFor the sample size calculation we assumed that for patients with an adverse event, 24-month progression-free survival information will be available and used for the sample size calculation.\n\n3.5.5.1 Stopping boundaries phase-II\nWe assumed the following parameters for the excess adverse event proportion stopping in the experimental arm:\n\n\n\n\n\n\n\nParameter\nValue\n\n\n\n\nExcess threshold\n25%\n\n\nBeta prior parameters\na=0.2, b=0.8\n\n\nInitial interim sample size\nn=25\n\n\nFinal sample size\nn=50\n\n\n\\(\\theta_{T_{Non-safe}}\\)\n60%\n\n\n\\(\\theta_{S}\\)\n60%\n\n\n\nThis gives us the following stopping boundaries based on the predictive probability:\n\n\nShow R code\np_max &lt;- c(0.25)\n\n# Prior information\na_1 &lt;- 0.2\nb_1 &lt;- 0.8\n\nx &lt;- seq(0,1,0.001)\n\nn_initial &lt;- 25\nr &lt;- 0:n_initial\nn_increase &lt;- 25\n\nn_max &lt;- 50\nn &lt;- seq(n_initial, n_max, n_increase)\nr &lt;- 0:n_max\nm &lt;- n_max-r\n\n#### Scenario\ntheta_T &lt;- 0.6\n\n\n\ndata &lt;- expand.grid(n=n, r=r) %&gt;% arrange(n) %&gt;% \n  filter(n&gt;=r) %&gt;% mutate(i=n_max-n+1)\ndata &lt;- expandRows(data, count=3)\ndata &lt;- data %&gt;% group_by(n, r) %&gt;% \n  mutate(m=n_max-n, ind=1, i=cumsum(ind)-1, ind=NULL)\n\ndata &lt;- data %&gt;% \n  mutate(PS1=dbbinom(i, size=m, alpha=a_1+r, beta=b_1+n-r), \n                        Ti=1-pbeta(p_max, a_1+r+i, b_1+n_max-r-i), \n                        ind=ifelse(Ti&gt;theta_T, 1, 0), n_max)\n\ndata &lt;- data %&gt;% select(n_max, n, r, m, i, Ti, PS1, ind)\n\nthreshold_safety &lt;- 0.6\n\ndata_pp &lt;- data %&gt;% group_by(n_max, n, r) %&gt;% summarise(pp=round(sum(PS1*ind),6), \n                                                 stop_pp=ifelse(pp&gt;threshold_safety, 1, 0))\n\n\nstop_boundaries0 &lt;- data_pp %&gt;% filter(stop_pp==1) %&gt;%\n  group_by(n_max, n) %&gt;% summarise(r=min(r), stop=NULL)\n\nnames(stop_boundaries0) &lt;- c(\"Maximal sample size\", \"Interim sample size\", \"Stopping boundary\")\nstop_boundaries0\n\n\n# A tibble: 2 × 3\n# Groups:   Maximal sample size [1]\n  `Maximal sample size` `Interim sample size` `Stopping boundary`\n                  &lt;dbl&gt;                 &lt;dbl&gt;               &lt;int&gt;\n1                    50                    25                   8\n2                    50                    50                  14\n\n\n\n\n\n3.5.6 Priors\nWe use the following priors for the simulation\n\n3.5.6.1 Beta prior for excess adverse event stopping\nAs mentioned in the section of ‘available evidence’ there is some evidence for the adverse event proportion in the experimental arm. We assumed a slighty more conservative mean value of 0.2 with a prior weight of 1 patient from a beta prior with a=0.2 and b=0.8.\n\n\n3.5.6.2 Gaussian prior on hazard ratio for disease-free survival\n\n\nShow R code\nrate_event_0 &lt;- 1/30\nrate_event_1 &lt;- 1/47\nexpected_event_rate &lt;- 0.5*(pexp(24, rate_event_0)+pexp(24, rate_event_1))\n\nprior_mean &lt;- log(0.8)\nprior_weight &lt;- 90\n\nprior_sd &lt;- 2/sqrt(prior_weight*expected_event_rate)\n\n\nFor the prior on the hazard ratio for disease-free survival we assumed a Gaussian distribution centered on a mean of \\(log(0.8)\\) with a standard deviation of \\(0.31\\), which is based on the expected event rate with a prior weight of \\(90\\) patients. This leads to a probability that the prior log hazard ratio is greater than 0 of \\(0.23\\).\n\n\nShow R code\nx &lt;- seq(-1.5, 1, 0.001)\n\ndata_plot &lt;- tibble(x=x, y=dnorm(x, prior_mean, prior_sd))\n# data_plot$x &lt;- exp(data_plot$x)\n# data_plot$y &lt;- exp(data_plot$y)\n\nggplot(data_plot, aes(x, y))+geom_line()+theme_bw()+xlab(\"Log hazard ratio\")+ylab(\"Density\")+geom_vline(xintercept = 0, linetype=\"dashed\")+theme(panel.grid.minor = element_blank())+ggtitle(\"Prior on hazard ratio\")",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Seamless phase-II/III study</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-Seamless.html#primary-endpoint",
    "href": "01-SampleSize-Seamless.html#primary-endpoint",
    "title": "3  Seamless phase-II/III study",
    "section": "4.1 Primary endpoint",
    "text": "4.1 Primary endpoint\nDisease-free survival at 24-months",
    "crumbs": [
      "Sample size",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Seamless phase-II/III study</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-Seamless.html#safety-endpoint",
    "href": "01-SampleSize-Seamless.html#safety-endpoint",
    "title": "3  Seamless phase-II/III study",
    "section": "4.2 Safety endpoint",
    "text": "4.2 Safety endpoint\nAdverse events in experimental arm (early stopping in phase-II)",
    "crumbs": [
      "Sample size",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Seamless phase-II/III study</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-Seamless.html#hypotheses",
    "href": "01-SampleSize-Seamless.html#hypotheses",
    "title": "3  Seamless phase-II/III study",
    "section": "3.3 Hypotheses",
    "text": "3.3 Hypotheses\nWe consider the following one-sided hypotheses for the phase-III trial\n\nNull hypothesis: Log hazard ratio \\(\\theta\\) between experimental arm and control arm is greater or equal than zero, that is, \\(H_0: \\theta \\geq 0\\),\nAlternative hypothesis: Log hazard ratio \\(\\theta\\) between experimental arm and control arm is smaller than zero, that is, \\(H_0: \\theta&lt;0\\).",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Seamless phase-II/III study</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-Seamless.html#endpoints",
    "href": "01-SampleSize-Seamless.html#endpoints",
    "title": "3  Seamless phase-II/III study",
    "section": "3.2 Endpoints",
    "text": "3.2 Endpoints\nPrimary endpoint: Disease-free survival at 24-months (phase-III endpoint)\nSafety endpoint: Adverse events in experimental arm (for phase-II part)",
    "crumbs": [
      "Sample size",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Seamless phase-II/III study</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-Seamless.html#endpoints-and-testing-hierarchy",
    "href": "01-SampleSize-Seamless.html#endpoints-and-testing-hierarchy",
    "title": "3  Seamless phase-II/III study",
    "section": "3.2 Endpoints and testing hierarchy",
    "text": "3.2 Endpoints and testing hierarchy\nSafety endpoint: Adverse events in experimental arm (for phase-II part)\nPrimary endpoint: Disease-free survival at 24-months (phase-III endpoint)\nOf note, these are not co-primary endpoints, because the safety endpoint is not required to define a trial success. But we test the endpoints in a hierarchical way: Only if the probability for an excess adverse event proportion is below a given threshold, the primary endpoint will be assessed for futility assessment.",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Seamless phase-II/III study</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-Seamless.html#trial-structure",
    "href": "01-SampleSize-Seamless.html#trial-structure",
    "title": "3  Seamless phase-II/III study",
    "section": "3.4 Trial structure",
    "text": "3.4 Trial structure\n\n\n\n\n\ngantt\n    title Seamless Phase-II/III design\n    dateFormat X\n    axisFormat %s\n    section Phase-II\n    Interim phase-II: active, 0, 50\n    Phase-II: 0, 100\n    Evaluation for Phase-III: crit, 0, 100\n    section Phase-III\n    Phase-III: 0, 360",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Seamless phase-II/III study</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-Seamless.html#results",
    "href": "01-SampleSize-Seamless.html#results",
    "title": "3  Seamless phase-II/III study",
    "section": "3.6 Results",
    "text": "3.6 Results\nWe simulated 1,000 trials with the above specification parameters and report the following trial operating characteristics:\n\n\n\n\n\n\n\nParameter\nValue\n\n\n\n\nProbability of stopping at interim analysis (phase-II) because of safety under null hypothesis\n5.8%\n\n\nProbability of stopping (phase-II) because of safety under null hypothesis\n15.4%\n\n\nProbability of starting a phase-III trial under null hypothesis\n43.1%\n\n\nProbability of not-starting a phase-III trial because of futility under null hypothesis\n27.7%\n\n\nProbability of successful phase-III trial under the null hypothesis\n3%\n\n\nProbability of successful phase-III trial under the alternative hypothesis\n81%\n\n\n\\(\\epsilon_{fut}\\)\n10%\n\n\n\\(\\epsilon_{success}\\)\n2.5%",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Seamless phase-II/III study</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-Seamless.html#comparison-with-frequentist-phase-ii-trial",
    "href": "01-SampleSize-Seamless.html#comparison-with-frequentist-phase-ii-trial",
    "title": "3  Seamless phase-II/III study",
    "section": "3.7 Comparison with frequentist phase-II trial",
    "text": "3.7 Comparison with frequentist phase-II trial\nWe compare our seamless phase-II/III design simulation results with a sample size calculation from a ‘classic’ frequentist phase-III design with a one-sided logrank test (\\(\\alpha=0.025\\), \\(1-\\beta=0.8\\)$ using the artsurv command in Stata:\nartsurv, method(l) edf0(0.45) hr(1,0.64) np(2) recrt(0 0, 1, 0 ) onesided(1) alpha(0.025) power(0.8)\nThis command gives a calculated total sample size of 336 patients with an expected total number of events of 160 events.",
    "crumbs": [
      "Sample size",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Seamless phase-II/III study</span>"
    ]
  },
  {
    "objectID": "01-SampleSize-Seamless.html#comparison-with-frequentist-phase-iii-trial",
    "href": "01-SampleSize-Seamless.html#comparison-with-frequentist-phase-iii-trial",
    "title": "3  Seamless phase-II/III study",
    "section": "3.7 Comparison with frequentist phase-III trial",
    "text": "3.7 Comparison with frequentist phase-III trial\nWe compare our seamless phase-II/III design simulation results with a sample size calculation from a ‘classic’ frequentist phase-III design with a one-sided logrank test (\\(\\alpha=0.025\\), \\(1-\\beta=0.8\\)) using the artsurv command in Stata:\nartsurv, method(l) edf0(0.45) hr(1,0.64) np(2) recrt(0 0, 1, 0 ) onesided(1) alpha(0.025) power(0.8)\nThis command gives a calculated total sample size of 336 patients with an expected total number of events of 160 events.",
    "crumbs": [
      "Sample size and power",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Seamless phase-II/III study</span>"
    ]
  }
]